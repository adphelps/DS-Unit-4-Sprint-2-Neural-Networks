{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2*\n",
    "\n",
    "# Sprint Challenge - Neural Network Foundations\n",
    "\n",
    "Table of Problems\n",
    "\n",
    "1. [Defining Neural Networks](#Q1)\n",
    "2. [Chocolate Gummy Bears](#Q2)\n",
    "    - Perceptron\n",
    "    - Multilayer Perceptron\n",
    "4. [Keras MMP](#Q3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Q1\"></a>\n",
    "## 1. Define the following terms:\n",
    "\n",
    "- **Neuron:**the main component of a neural network. takes in a value from the previous layer, performs a set computation on the value, and outputs a new value to the next layer.\n",
    "- **Input Layer:**the first layer of a neural network where the information is fed in\n",
    "- **Hidden Layer:**a group of neurons that take in a set of weighted inputs and produce an output through an activation function. every layer of neurons between the input layer and the output layer is a hidden layer.\n",
    "- **Output Layer:**the final layer of a neural network which yields the output\n",
    "- **Activation:** defines the output of a neuron for a given input.\n",
    "- **Backpropagation:**the process used to train neural networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chocolate Gummy Bears <a id=\"Q2\"></a>\n",
    "\n",
    "Right now, you're probably thinking, \"yuck, who the hell would eat that?\". Great question. Your candy company wants to know too. And you thought I was kidding about the [Chocolate Gummy Bears](https://nuts.com/chocolatessweets/gummies/gummy-bears/milk-gummy-bears.html?utm_source=google&utm_medium=cpc&adpos=1o1&gclid=Cj0KCQjwrfvsBRD7ARIsAKuDvMOZrysDku3jGuWaDqf9TrV3x5JLXt1eqnVhN0KM6fMcbA1nod3h8AwaAvWwEALw_wcB). \n",
    "\n",
    "Let's assume that a candy company has gone out and collected information on the types of Halloween candy kids ate. Our candy company wants to predict the eating behavior of witches, warlocks, and ghosts -- aka costumed kids. They shared a sample dataset with us. Each row represents a piece of candy that a costumed child was presented with during \"trick\" or \"treat\". We know if the candy was `chocolate` (or not chocolate) or `gummy` (or not gummy). Your goal is to predict if the costumed kid `ate` the piece of candy. \n",
    "\n",
    "If both chocolate and gummy equal one, you've got a chocolate gummy bear on your hands!?!?!\n",
    "![Chocolate Gummy Bear](https://ed910ae2d60f0d25bcb8-80550f96b5feb12604f4f720bfefb46d.ssl.cf1.rackcdn.com/3fb630c04435b7b5-2leZuM7_-zoom.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "candy = pd.read_csv('chocolate_gummy_bears.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chocolate</th>\n",
       "      <th>gummy</th>\n",
       "      <th>ate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chocolate  gummy  ate\n",
       "0          0      1    1\n",
       "1          1      0    1\n",
       "2          0      1    1\n",
       "3          0      0    0\n",
       "4          1      1    0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron\n",
    "\n",
    "To make predictions on the `candy` dataframe. Build and train a Perceptron using numpy. Your target column is `ate` and your features: `chocolate` and `gummy`. Do not do any feature engineering. :P\n",
    "\n",
    "Once you've trained your model, report your accuracy. You will not be able to achieve more than ~50% with the simple perceptron. Explain why you could not achieve a higher accuracy with the *simple perceptron* architecture, because it's possible to achieve ~95% accuracy on this dataset. Provide your answer in markdown (and *optional* data anlysis code) after your perceptron implementation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# Start your candy perceptron here\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = candy[['chocolate', 'gummy']].values\n",
    "y = candy['ate'].values\n",
    "\n",
    "X_train, X_test = train_test_split(X, train_size=0.8, test_size=0.2)\n",
    "X_train, X_val = train_test_split(X_train, train_size=0.8, test_size=0.2)\n",
    "y_train, y_test = train_test_split(y, train_size=0.8, test_size=0.2)\n",
    "y_train, y_val = train_test_split(y_train, train_size=0.8, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.51125\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Perceptron:\n",
    "  \n",
    "  #constructor\n",
    "  def __init__ (self):\n",
    "    self.w = None\n",
    "    self.b = None\n",
    "    \n",
    "  #model  \n",
    "  def model(self, x):\n",
    "    return 1 if (np.dot(self.w, x) >= self.b) else 0\n",
    "  \n",
    "  #predictor to predict on the data based on w\n",
    "  def predict(self, X):\n",
    "    Y = []\n",
    "    for x in X:\n",
    "      result = self.model(x)\n",
    "      Y.append(result)\n",
    "    return np.array(Y)\n",
    "    \n",
    "  def fit(self, X, Y, epochs = 1, lr = 1):\n",
    "    self.w = np.ones(X.shape[1])\n",
    "    self.b = 0\n",
    "    accuracy = {}\n",
    "    max_accuracy = 0\n",
    "    wt_matrix = []\n",
    "    #for all epochs\n",
    "    for i in range(epochs):\n",
    "      for x, y in zip(X, Y):\n",
    "        y_pred = self.model(x)\n",
    "        if y == 1 and y_pred == 0:\n",
    "          self.w = self.w + lr * x\n",
    "          self.b = self.b - lr * 1\n",
    "        elif y == 0 and y_pred == 1:\n",
    "          self.w = self.w - lr * x\n",
    "          self.b = self.b + lr * 1\n",
    "          \n",
    "      wt_matrix.append(self.w)    \n",
    "      accuracy[i] = accuracy_score(self.predict(X), Y)\n",
    "      if (accuracy[i] > max_accuracy):\n",
    "        max_accuracy = accuracy[i]\n",
    "        chkptw = self.w\n",
    "        chkptb = self.b\n",
    "    #checkpoint (Save the weights and b value)\n",
    "    self.w = chkptw\n",
    "    self.b = chkptb\n",
    "    \n",
    "    #return the weight matrix, that contains weights over all epochs\n",
    "    return np.array(wt_matrix)\n",
    "\n",
    "model = Perceptron()\n",
    "model.fit(X_train, y_train, 50, 0.1)\n",
    "y_pred = model.predict(X_val)\n",
    "print(accuracy_score(y_pred, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this model probably needs a way to learn, like backpropogation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron <a id=\"Q3\"></a>\n",
    "\n",
    "Using the sample candy dataset, implement a Neural Network Multilayer Perceptron class that uses backpropagation to update the network's weights. Your Multilayer Perceptron should be implemented in Numpy. \n",
    "Your network must have one hidden layer.\n",
    "\n",
    "Once you've trained your model, report your accuracy. Explain why your MLP's performance is considerably better than your simple perceptron's on the candy dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self):\n",
    "        # Set up Architecture of Neural Network\n",
    "        self.input = 2\n",
    "        self.hiddenNodes = 6 \n",
    "        self.outputNodes = 1\n",
    "        \n",
    "        # Initial Weights\n",
    "        self.weights1 = np.random.randn(self.input,self.hiddenNodes)\n",
    "        self.weights2 = np.random.randn(self.hiddenNodes, self.outputNodes)\n",
    "        \n",
    "\n",
    "    def sigmoid(self, s):\n",
    "        return 1 / (1+np.exp(-s))\n",
    "    \n",
    "    \n",
    "    def sigmoidPrime(self, s):\n",
    "        return s * (1 - s)\n",
    "    \n",
    "    \n",
    "    def feed_forward(self,X):\n",
    "        \"\"\"\n",
    "        Calculate the NN inference using feed forward.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Weighted sum of inputs & hidden\n",
    "        self.hidden_sum = np.dot(X, self.weights1)\n",
    "        \n",
    "        # Activations of weighted sum\n",
    "        self.activated_hidden = self.sigmoid(self.hidden_sum)\n",
    "        \n",
    "        # Weighted sum between hidden and output\n",
    "        self.output_sum = np.dot(self.activated_hidden, self.weights2)\n",
    "        \n",
    "        # Final Activation of output\n",
    "        self.activated_output = self.sigmoid(self.output_sum)\n",
    "        \n",
    "        return self.activated_output\n",
    "    \n",
    "    \n",
    "    def backward(self, X, y, o):\n",
    "        \"\"\"\n",
    "        Backward propagate through the network\n",
    "        \"\"\"\n",
    "        self.o_error = y - o #error in output\n",
    "        self.o_delta = self.o_error * self.sigmoidPrime(o) # apply derivative of sigmoid to error\n",
    "        \n",
    "        self.z2_error = self.o_delta.dot(self.weights2.T) # z2 error: how much our hidden layer weights were off\n",
    "        self.z2_delta = self.z2_error*self.sigmoidPrime(self.activated_hidden)\n",
    "        \n",
    "        self.weights1 += X.T.dot(self.z2_delta) #Adjust first set (input => hidden) weights\n",
    "        self.weights2 += self.activated_hidden.T.dot(self.o_delta) #adjust second set (hidden => output) weights\n",
    "        \n",
    "        \n",
    "    def train(self, X, y):\n",
    "        o = self.feed_forward(X)\n",
    "        self.backward(X, y, o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n",
      "output [0.60114423]\n"
     ]
    }
   ],
   "source": [
    "X = candy[['chocolate', 'gummy']].values\n",
    "y = candy['ate'].values\n",
    "\n",
    "X = X.astype('float64')\n",
    "y = y.astype('float64')\n",
    "y3 = np.reshape(y, (10000,1))\n",
    "nn = NeuralNetwork()\n",
    "\n",
    "print(X[0])\n",
    "output = nn.feed_forward(X[0])\n",
    "print(\"output\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.39885577])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = y3[0] - output\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.60114423]\n",
      " [0.5364404 ]\n",
      " [0.60114423]\n",
      " ...\n",
      " [0.60114423]\n",
      " [0.60114423]\n",
      " [0.5364404 ]]\n",
      "[[0.39885577]\n",
      " [0.4635596 ]\n",
      " [0.39885577]\n",
      " ...\n",
      " [0.39885577]\n",
      " [0.39885577]\n",
      " [0.4635596 ]]\n"
     ]
    }
   ],
   "source": [
    "output_all = nn.feed_forward(X)\n",
    "error_all = y3 - output_all\n",
    "print(output_all)\n",
    "print(error_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P.S. Don't try candy gummy bears. They're disgusting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Keras MMP <a id=\"Q3\"></a>\n",
    "\n",
    "Implement a Multilayer Perceptron architecture of your choosing using the Keras library. Train your model and report its baseline accuracy. Then hyperparameter tune at least two parameters and report your model's accuracy.\n",
    "Use the Heart Disease Dataset (binary classification)\n",
    "Use an appropriate loss function for a binary classification task\n",
    "Use an appropriate activation function on the final layer of your network.\n",
    "Train your model using verbose output for ease of grading.\n",
    "Use GridSearchCV or RandomSearchCV to hyperparameter tune your model. (for at least two hyperparameters)\n",
    "When hyperparameter tuning, show you work by adding code cells for each new experiment.\n",
    "Report the accuracy for each combination of hyperparameters as you test them so that we can easily see which resulted in the highest accuracy.\n",
    "You must hyperparameter tune at least 3 parameters in order to get a 3 on this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>197</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>177</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>140</td>\n",
       "      <td>308</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>271</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>182</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>178</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "290   61    1   0       148   203    0        1      161      0      0.0   \n",
       "200   44    1   0       110   197    0        0      177      0      0.0   \n",
       "40    51    0   2       140   308    0        0      142      0      1.5   \n",
       "121   59    1   0       138   271    0        0      182      0      0.0   \n",
       "136   60    0   2       120   178    1        1       96      0      0.0   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "290      2   1     3       0  \n",
       "200      2   1     2       0  \n",
       "40       2   1     2       1  \n",
       "121      2   0     2       1  \n",
       "136      2   0     2       1  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv')\n",
    "df = df.sample(frac=1)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 242 samples\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 2ms/sample - loss: 0.6932 - accuracy: 0.4959\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 66us/sample - loss: 0.6929 - accuracy: 0.5372\n",
      "Epoch 3/50\n",
      "242/242 [==============================] - 0s 66us/sample - loss: 0.6927 - accuracy: 0.5372\n",
      "Epoch 4/50\n",
      "242/242 [==============================] - 0s 58us/sample - loss: 0.6924 - accuracy: 0.5413\n",
      "Epoch 5/50\n",
      "242/242 [==============================] - 0s 70us/sample - loss: 0.6922 - accuracy: 0.5413\n",
      "Epoch 6/50\n",
      "242/242 [==============================] - 0s 66us/sample - loss: 0.6919 - accuracy: 0.5413\n",
      "Epoch 7/50\n",
      "242/242 [==============================] - 0s 70us/sample - loss: 0.6919 - accuracy: 0.5413\n",
      "Epoch 8/50\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 0.6917 - accuracy: 0.5372\n",
      "Epoch 9/50\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 0.6915 - accuracy: 0.5413\n",
      "Epoch 10/50\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 0.6915 - accuracy: 0.5372\n",
      "Epoch 11/50\n",
      "242/242 [==============================] - 0s 62us/sample - loss: 0.6913 - accuracy: 0.5413\n",
      "Epoch 12/50\n",
      "242/242 [==============================] - 0s 66us/sample - loss: 0.6911 - accuracy: 0.5413\n",
      "Epoch 13/50\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 0.6910 - accuracy: 0.5413\n",
      "Epoch 14/50\n",
      "242/242 [==============================] - 0s 66us/sample - loss: 0.6908 - accuracy: 0.5413\n",
      "Epoch 15/50\n",
      "242/242 [==============================] - 0s 62us/sample - loss: 0.6910 - accuracy: 0.5372\n",
      "Epoch 16/50\n",
      "242/242 [==============================] - 0s 94us/sample - loss: 0.6905 - accuracy: 0.5455\n",
      "Epoch 17/50\n",
      "242/242 [==============================] - 0s 62us/sample - loss: 0.6906 - accuracy: 0.5413\n",
      "Epoch 18/50\n",
      "242/242 [==============================] - 0s 62us/sample - loss: 0.6905 - accuracy: 0.5413\n",
      "Epoch 19/50\n",
      "242/242 [==============================] - 0s 62us/sample - loss: 0.6903 - accuracy: 0.5413\n",
      "Epoch 20/50\n",
      "242/242 [==============================] - 0s 74us/sample - loss: 0.6902 - accuracy: 0.5413\n",
      "Epoch 21/50\n",
      "242/242 [==============================] - 0s 70us/sample - loss: 0.6901 - accuracy: 0.5413\n",
      "Epoch 22/50\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 0.6900 - accuracy: 0.5413\n",
      "Epoch 23/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.6899 - accuracy: 0.5413\n",
      "Epoch 24/50\n",
      "242/242 [==============================] - 0s 78us/sample - loss: 0.6898 - accuracy: 0.5413\n",
      "Epoch 25/50\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 0.6897 - accuracy: 0.5413\n",
      "Epoch 26/50\n",
      "242/242 [==============================] - 0s 62us/sample - loss: 0.6896 - accuracy: 0.5413\n",
      "Epoch 27/50\n",
      "242/242 [==============================] - 0s 72us/sample - loss: 0.6895 - accuracy: 0.5413\n",
      "Epoch 28/50\n",
      "242/242 [==============================] - 0s 58us/sample - loss: 0.6895 - accuracy: 0.5413\n",
      "Epoch 29/50\n",
      "242/242 [==============================] - 0s 66us/sample - loss: 0.6894 - accuracy: 0.5413\n",
      "Epoch 30/50\n",
      "242/242 [==============================] - 0s 95us/sample - loss: 0.6892 - accuracy: 0.5413\n",
      "Epoch 31/50\n",
      "242/242 [==============================] - 0s 74us/sample - loss: 0.6892 - accuracy: 0.5413\n",
      "Epoch 32/50\n",
      "242/242 [==============================] - 0s 64us/sample - loss: 0.6891 - accuracy: 0.5413\n",
      "Epoch 33/50\n",
      "242/242 [==============================] - 0s 66us/sample - loss: 0.6892 - accuracy: 0.5413\n",
      "Epoch 34/50\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 0.6889 - accuracy: 0.5413\n",
      "Epoch 35/50\n",
      "242/242 [==============================] - 0s 58us/sample - loss: 0.6888 - accuracy: 0.5413\n",
      "Epoch 36/50\n",
      "242/242 [==============================] - 0s 62us/sample - loss: 0.6888 - accuracy: 0.5413\n",
      "Epoch 37/50\n",
      "242/242 [==============================] - 0s 66us/sample - loss: 0.6886 - accuracy: 0.5413\n",
      "Epoch 38/50\n",
      "242/242 [==============================] - 0s 72us/sample - loss: 0.6886 - accuracy: 0.5413\n",
      "Epoch 39/50\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 0.6884 - accuracy: 0.5413\n",
      "Epoch 40/50\n",
      "242/242 [==============================] - 0s 66us/sample - loss: 0.6884 - accuracy: 0.5413\n",
      "Epoch 41/50\n",
      "242/242 [==============================] - 0s 58us/sample - loss: 0.6883 - accuracy: 0.5413\n",
      "Epoch 42/50\n",
      "242/242 [==============================] - 0s 78us/sample - loss: 0.6882 - accuracy: 0.5413\n",
      "Epoch 43/50\n",
      "242/242 [==============================] - 0s 58us/sample - loss: 0.6881 - accuracy: 0.5413\n",
      "Epoch 44/50\n",
      "242/242 [==============================] - 0s 70us/sample - loss: 0.6880 - accuracy: 0.5413\n",
      "Epoch 45/50\n",
      "242/242 [==============================] - 0s 66us/sample - loss: 0.6880 - accuracy: 0.5413\n",
      "Epoch 46/50\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 0.6878 - accuracy: 0.5413\n",
      "Epoch 47/50\n",
      "242/242 [==============================] - 0s 66us/sample - loss: 0.6878 - accuracy: 0.5413\n",
      "Epoch 48/50\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 0.6878 - accuracy: 0.5413\n",
      "Epoch 49/50\n",
      "242/242 [==============================] - 0s 70us/sample - loss: 0.6877 - accuracy: 0.5413\n",
      "Epoch 50/50\n",
      "242/242 [==============================] - 0s 66us/sample - loss: 0.6876 - accuracy: 0.5413\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.6889 - accuracy: 0.5574\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "\n",
    "X_train, X_test = train_test_split(df.drop(columns='target'), train_size=0.8, test_size=0.2)\n",
    "y_train, y_test = train_test_split(df['target'], train_size=0.8, test_size=0.2)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(X_train)\n",
    "scaler.fit_transform(X_test)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(13, input_dim=13, activation='sigmoid'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(2, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=50, verbose=True)\n",
    "scores = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim=13, activation='relu'))\n",
    "    model.add(Dense(5, activation='relu'))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "param_grid = {'batch_size': [60, 100],\n",
    "              'epochs': [40, 100],\n",
    "             }\n",
    "\n",
    "grid = GridSearchCV(estimator = model, param_grid=param_grid, n_jobs=4)\n",
    "grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.49625850319862364 using {'batch_size': 60, 'epochs': 100}\n",
      "Means: 0.49532312750816343, Stdev: 0.06973152048050725 with: {'batch_size': 60, 'epochs': 40}\n",
      "Means: 0.49625850319862364, Stdev: 0.06916324811586916 with: {'batch_size': 60, 'epochs': 100}\n",
      "Means: 0.49209184050559995, Stdev: 0.06315721096855095 with: {'batch_size': 100, 'epochs': 40}\n",
      "Means: 0.4756802678108215, Stdev: 0.07806910510041724 with: {'batch_size': 100, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "nteract": {
   "version": "0.15.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
